# Monocular Depth Estimation using ResNet50 Encoder-Decoder

This repository contains a PyTorch implementation for monocular depth estimation using a modified U-Net-like architecture with a ResNet50 backbone as the encoder. The goal is to predict a depth map for a given single RGB input image.

## Overview

The notebook performs the following steps:

1.  **Data Loading:** Defines a custom PyTorch `Dataset` (`DepthEstimationDataset`) to load RGB images and their corresponding grayscale depth maps from specified directories. It handles data transformations like resizing, normalization, and random horizontal flipping for data augmentation during training.
2.  **Model Architecture:** Implements a depth estimation model (`DepthEstimationModel`) based on an encoder-decoder structure.
    *   **Encoder:** Uses the first few blocks of a pre-trained ResNet50 model to extract features at different scales.
    *   **Decoder:** Consists of several up-sampling blocks (using bilinear upsampling followed by convolution, batch normalization, and ReLU activation) to progressively reconstruct the depth map. Skip connections are implicitly formed by the U-Net-like structure feeding features from corresponding encoder stages to the decoder stages (although direct concatenation isn't explicitly shown in the `forward` pass, the architecture follows this pattern).
    *   **Output:** A final convolutional layer predicts a single-channel depth map.
3.  **Training:** Implements a `train_model` function that trains the model using Mean Squared Error (MSE) loss and the Adam optimizer. It includes a validation loop to monitor performance on a separate validation set and prints training progress.
4.  **Prediction:** Provides a `generate_predictions` function to run inference on a test dataset (where depth maps are not available). It processes the model's raw output by:
    *   Resizing the predicted depth map to 128x128 pixels.
    *   Normalizing the depth values to the range [0, 1].
    *   Scaling the normalized values to [0, 255] and converting them to an 8-bit unsigned integer format (`uint8`).
5.  **Submission Formatting:** Includes a function (`images_to_csv_with_metadata`) to flatten the processed 128x128 predictions and save them into a CSV file (`predictions.csv`) in the format required for submission (likely for a competition), including an `id` column, the `ImageID` (filename), and 16384 columns representing the flattened pixel values.

## Model Architecture Details

*   **Encoder:** Pre-trained ResNet50 (layers `conv1`, `bn1`, `relu`, `maxpool`, `layer1`, `layer2`, `layer3`, `layer4`).
*   **Decoder:** 5 decoder blocks using `Upsample` (bilinear, scale\_factor=2), `Conv2d`, `BatchNorm2d`, `ReLU`.
*   **Final Layer:** `Conv2d` with 1 output channel.
*   **Input Size:** Expects 3-channel RGB images, resized to 256x256 during preprocessing.
*   **Output Size (Model):** Produces a single-channel depth map with spatial dimensions determined by the input size and network architecture (likely smaller than 256x256 before the final resize in `generate_predictions`).
*   **Output Size (Processed):** Processed predictions are 128x128 grayscale images (uint8).

## Dataset

The code assumes the dataset is organized into `training`, `validation`, and `testing` sets, each containing an `images` subdirectory. The `training` and `validation` directories are also expected to have a `depths` subdirectory containing the ground truth depth maps (as grayscale images).

The paths used in the notebook are specific to the Kaggle environment:
*   Training Images: `/kaggle/input/depth-estimation/competition-data/competition-data/training/images`
*   Training Depths: `/kaggle/input/depth-estimation/competition-data/competition-data/training/depths`
*   Validation Images: `/kaggle/input/depth-estimation/competition-data/competition-data/validation/images`
*   Validation Depths: `/kaggle/input/depth-estimation/competition-data/competition-data/validation/depths`
*   Testing Images: `/kaggle/input/depth-estimation/competition-data/competition-data/testing/images`

## Dependencies

*   Python 3.x
*   PyTorch (`torch`, `torchvision`)
*   NumPy (`numpy`)
*   OpenCV (`cv2`)
*   Pandas (`pandas`)
*   Pillow (`PIL`)
*   Matplotlib (`matplotlib`) - for potential plotting, though not used for final output.

## How to Run

1.  **Environment Setup:** Ensure Python and all the required dependencies are installed. A GPU is highly recommended for efficient training.
    ```bash
    pip install torch torchvision opencv-python numpy pandas pillow matplotlib
    ```
2.  **Data Setup:** Place the dataset in the directory structure mentioned above or modify the paths in **Cell 8** of the notebook (`.ipynb` file) accordingly.
3.  **Execution:** Run the cells of the notebook (`22f3002350-ga11.ipynb`) sequentially using a Jupyter environment (like Jupyter Lab, Jupyter Notebook, or VS Code with Jupyter extension, or Kaggle Kernels).
    *   The notebook will load data, define the model, train it for 40 epochs (as configured in **Cell 10**), save the trained model weights to `depth_estimation_model.pth` (**Cell 11**), generate predictions on the test set, and save the formatted predictions to `predictions.csv` (**Cell 12**).
4.  **Configuration:** Key parameters like `batch_size`, `learning_rate`, and `num_epochs` can be adjusted in **Cells 8, 9, and 10**.

## Output

*   **Trained Model:** `depth_estimation_model.pth` - Contains the saved state dictionary of the trained PyTorch model.
*   **Predictions CSV:** `predictions.csv` - A CSV file where each row corresponds to a test image.
    *   `id`: A unique integer identifier for the row.
    *   `ImageID`: The filename of the original test image.
    *   `0` to `16383`: Columns representing the pixel values (0-255) of the predicted 128x128 depth map, flattened row by row.